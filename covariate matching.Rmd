
# Set up

Load packages
```{r}
suppressPackageStartupMessages({
  suppressWarnings({
    library(sf)          # Spatial data
  library(terra)       # Raster processing  
  library(spsurvey)    # Spatially balanced sampling
  library(MatchIt)     # Matching
  library(cobalt)      # Balance checking
  library(tidyverse)       # Data wrangling
  library(exactextractr) # Zonal stats
  library(rnaturalearth) # Country boundaries
  library(tmap)        # Making maps
  library(spsurvey)    # Spatially balanced sampling
  library(sandwich)
  library(lmtest)
  library(rmapshaper) # Spatial processing
  })})
```

Settings and universal variables
```{r}
tmap_mode(mode = "view")
tmap_options(check.and.fix = TRUE)

crs = 4326
crs_sampling = 9822 #needs to be a projected crs, so chose an equal area global one

options(scipen=999)
```

# Import & process data



## Covariates

Road density
```{r}
road_density_raw = rast("Raw data/Covariates/Road access/GRIP4_density_total/grip4_total_dens_m_km2.asc")
road_density = log(road_density_raw + 0.001)

rm(road_density_raw)
```

Distance to water
```{r}
dist_to_water = mean(rast("Raw data/Covariates/Distance to water/distance_to_water_reprojected.tif"))
```

Nightlights
```{r}
#nightlights = rast("Raw data/Covariates/Nightlights/VNL_npp_2024_global_vcmslcfg_v2_c202502261200.average_masked.dat.tif/VNL_npp_2024_global_vcmslcfg_v2_c202502261200.average_masked.dat.tif")
```

Protected areas
```{r, eval = F}
protected_areas_full = st_read("Raw data/Covariates/Protected areas/protected_areas_study_area_full.shp")%>%
  filter(st_is_valid(geometry))

protected_areas = rast("Raw data/Covariates/Protected areas/protected.tif")
protected_areas[is.na(protected_areas)] = 0
```

Land cover
```{r}
land_cover_path = "Raw data/Covariates/Land cover/MCD12C1.A2023001.061.2024251212901.hdf"
#gdal_subdatasets(land_cover_path)

land_cover = project(rast(land_cover_path, subds = "Majority_Land_Cover_Type_1"), "EPSG:4326")

forest_binary = as.numeric(land_cover %in% 1:5)  # Classes 1-5 are forest types (Evergreen Needleleaf to Mixed Forests)
cropland_binary = as.numeric(land_cover %in% c(12,14)) # Class 12 is cropland, 14 is cropland mosaic

water = as.numeric(land_cover == 0)
water[water == 0] = NA 
water_sf <- st_as_sf(as.polygons(water, dissolve = TRUE))

rm(land_cover)
rm(water)
```

USGS ECM deposits
```{r}
usgs_deposits = st_transform(st_read("Processed data/usgs_deposits_filtered.gpkg"), crs)
#%>%  filter(lengths(st_intersects(., study_area_adm1s_full)) > 0)
```

Population Density
```{r}
pop_dens = rast("Raw data/Covariates/Population density/gpw_v4_population_density_rev11_2020_30_sec_2020.tif")
```


## Dependent variable (mines)
```{r}
snp = st_transform(st_read("Processed data/snp_points_filtered.gpkg"), crs)
  #filter(lengths(st_intersects(., study_area_adm1s_full)) > 0)%>%
  #st_join(study_area_adm1s_full, largest = T)

maus = st_transform(st_read("Processed data/maus_polygons_filtered_joined.gpkg"), crs)%>%
  st_make_valid()
  #filter(lengths(st_intersects(., study_area_adm1s_full)) > 0)%>%
  #st_join(study_area_adm1s_full, largest = T)
```

## Independent variable (Landmark)

Load in our landmark datasets of Indigenous territories
```{r, eval = F}
#landmark_study_area_recog = st_transform(st_read("Processed data/Landmark processed/landmark_recog_study_area.shp"), crs)

#landmark_study_area_full = st_transform(st_read("Processed data/Landmark processed/landmark_and_garnett_full_study_area.shp"), crs)%>%filter(st_is_valid(geometry))

#garnett = st_transform(st_read("Raw data/Garnett et al/garnett_singlepart.shp"), crs)
```


## Study area

Define study area (based on adm1). We only want administrative areas that have at least one mine and one Indigenous territory, for both all territories and territories for which we have recognition data. 

So we create some new binary columns recording whether each adm1 intersects with a mine, indigenous territories, etc.
```{r}
adm1s_full <- st_transform(ne_download(scale = 10, type = "states", category = "cultural", returnclass = "sf"), crs)%>%
  st_make_valid()%>%
  mutate(geonunit = ifelse(is.na(geonunit), admin, geonunit),
         gn_name = ifelse(is.na(gn_name), name, gn_name))%>%
  select(gn_name, geonunit)%>%
  mutate(
    adm1_id = row_number(),
    maus = (st_intersects(geometry, maus) %>% lengths() > 0) %>% as.integer(),
    snp  = (st_intersects(geometry, snp) %>% lengths() > 0) %>% as.integer())
```

Due to computational constraints and broken geometries that sf struggles to handle, we're going to export this layer to ArcGIS Pro and create the columns for intersections with Indigenous territories there. 
```{r, eval = F}
st_write(adm1s_full, "Processed data/Study area/Intermediate/Adm1s, export to arcgis/adm1s_export_to_arcgis.shp", delete_dsn = T)
```

After doing that processing in ArcGIS Pro, we can now load our processed dataset back and filter for only adm1s that both contain ECM mines and intersect with Indigenous territories
```{r}
adm1s_arcgis = st_read("Processed data/Study area/Intermediate/Adm1s, export to arcgis/adm1s_export_to_arcgis.shp")%>%
  select(adm1_id, garnett, indic, comm)%>%
  rename(landmark_indicative = indic, landmark_community = comm)%>%
  st_drop_geometry()

adm1s_filtered = adm1s_full%>%
  left_join(., adm1s_arcgis, by = "adm1_id")%>%
  mutate(any_mine = ifelse(maus > 0 | snp > 0, 1, 0), 
         any_indig = ifelse(garnett + landmark_indicative + landmark_community > 0, 1, 0))%>%
  filter(any_mine == 1 & any_indig == 1)%>%
  filter(gn_name != "Chukotskiy Avtonomnyy Okrug")

tm_shape(adm1s_filtered)+
  tm_polygons()

rm(adm1s_arcgis, adm1s_full)
```
## Mines in study area

Let's filter our mine datasets (both Maus polygons and S&P points) to ensure that we're only considering mines that intersect the study area. 

For Maus, we'll also consolidate any duplicates based on the 'Local ID' column as well, and conduct a spatial join to bring in the adm1 and country data. 
```{r}
maus_study_area = maus%>%
  st_filter(., adm1s_filtered, .predicate = st_intersects)%>%
  rename(primary_commodity = Primary.Co)

maus_filtered = maus_study_area%>%
  filter(!is.na(LocalID))%>%
  group_by(LocalID, primary_commodity)%>%
  summarise(geom = st_union(geom))%>%
  ungroup()%>%
  select(primary_commodity)%>%
  rbind(., maus_study_area%>%filter(is.na(LocalID))%>%select(primary_commodity))%>%
  #mutate(id = row_number())%>%
  st_join(., adm1s_filtered%>%select(adm1_id, gn_name, geonunit))
  
st_write(maus_filtered, "Processed data/Mines/maus_study_area.gpkg", delete_dsn = T)
rm(maus)
```

Now, for the S&P dataset, we also filter for points in the study area, and get rid of any duplicates, as defined by any mining points that are both 1) within or right next to (within 1km) a Maus mining polygon, AND 2) share the same primary commodity as the Maus polygon they're in/next to.
```{r}
snp_study_area = snp%>%
  rename(primary_commodity = Primary.Co)%>%
  select(primary_commodity)%>%
  mutate(snp_id = row_number())%>%
  st_filter(., adm1s_filtered, .predicate = st_intersects)%>%
  st_join(., adm1s_filtered%>%select(adm1_id, gn_name, geonunit))

snp_in_maus = snp_study_area%>%
  st_join(., st_buffer(maus_study_area, 1000))%>%
  filter(primary_commodity.x == primary_commodity.y)
  
snp_filtered = snp_study_area%>%
  filter(!snp_id %in% snp_in_maus$snp_id)%>%
  select(-snp_id)

st_write(snp_filtered, "Processed data/Mines/snp_study_area.gpkg", delete_dsn = T)
rm(snp_in_maus, snp_study_area, snp, maus_study_area)
```

Load the processed mining datasets back in and map to confirm everything looks good
```{r}
maus_filtered = st_read("Processed data/Mines/maus_study_area.gpkg")
snp_filtered = st_read("Processed data/Mines/snp_study_area.gpkg")

tm_shape(maus_filtered%>%filter(geonunit == "Argentina"))+
  tm_polygons()+
  tm_shape(st_buffer(maus_filtered%>%filter(geonunit == "Argentina"), 1000))+
  tm_borders()+
  tm_shape(snp_filtered%>%filter(geonunit == "Argentina"))+
  tm_dots()+
  tm_basemap("Esri.WorldImagery")
```

Last, let's count how many mines are in each adm1, so that we can calibrate the proportion of how many samples to take in non-mining areas. 
```{r}
adm1s_filtered$n_mines = lengths(st_intersects(adm1s_filtered, rbind(maus_filtered%>%select(geom), snp_filtered%>%select(geom))))
adm1s_filtered$n_sample = adm1s_filtered$n_mines * 2

st_write(adm1s_filtered, "Processed data/Study area/adm1s_filtered.gpkg", delete_dsn = T)
adm1s_filtered = st_read("Processed data/Study area/adm1s_filtered.gpkg")
```

# Sampling points

So eventually, we want to match mines to 'non-mines'. 

Let's start off this process by separating our study area in mining areas and non-mining areas.

## Mines

First, let's set a sampling location for each mine.

The S&P dataset is already points so we can sample random points from the Maus dataset (one from each mine) and combine the two.

Sampling one random point per Maus mine
```{r}
set.seed(1236)

# Sample one point per polygon
sampled_pts <- lapply(st_geometry(maus_filtered), function(poly) {
  pt <- st_sample(poly, size = 1, type = "random", exact = TRUE)
  if (length(pt) == 0) st_point(c(NA_real_, NA_real_)) else pt[[1]]})

# Create a new sf object (copying attributes if desired)
maus_sampling_pts = st_sf(geometry = st_sfc(sampled_pts, crs = st_crs(maus_filtered)))%>%
  st_join(., maus_filtered)

rm(sampled_pts)
```

Map check to make sure everything looks good
```{r}
tm_shape(maus_filtered%>%filter(gn_name == "Otago"))+
  tm_polygons()+
  tm_shape(maus_sampling_pts%>%filter(gn_name == "Otago"))+
  tm_dots()
```

Combining with deduplicated S&P points to generate 1 dataset with all mining sampling points with covariates
```{r}
comb_mining_sampling_pts = rbind(
  maus_sampling_pts%>%
    rename(geom = geometry)%>%
    mutate(dataset = "maus"), 
  snp_filtered%>%
    mutate(dataset = "snp"))%>%
  mutate(mine_id = row_number())

st_write(comb_mining_sampling_pts, "Processed data/Sampling points/comb_mining_sampling_pts.gpkg", delete_dsn = T)
comb_mining_sampling_pts = st_read("Processed data/Sampling points/comb_mining_sampling_pts.gpkg")
```


## Non-Mines

We now want to generate the remaining sampling points as a spatially-balanced sample from non-mining areas. 

To do that, we're going to exclude any areas within 10km of mines. 

So first, let's generate a 10km buffer around each mine. 
```{r}
mine_buffer = rbind(snp_filtered, maus_filtered)%>%
  st_buffer(., dist = 10000)

st_write(mine_buffer, "Processed data/Mines/mine_buffer_10km.gpkg", delete_dsn = T)
```

Now we can remove these mining areas to generate non-mine areas within our study adm1s. 
```{r}
non_mine_full = st_difference(adm1s_filtered, st_union(mine_buffer)%>%st_make_valid())%>%
  mutate(area = st_area(.))%>%
  group_by(adm1_id, gn_name, geonunit) %>%
  filter(area == min(area))%>%  # The difference polygon is usually smaller
  ungroup()%>%
  select(-area)
```


Now, we want to remove any water from the study area so we don't sample there. 
```{r}
adm1s_no_water = rmapshaper::ms_erase(non_mine_full, water_sf)%>%
  st_make_valid()
rm(adm1s_filtered)

st_write(adm1s_no_water, "Processed data/Study area/nonmines_no_water.gpkg", delete_dsn = T)
adm1s_no_water = st_read("Processed data/Study area/nonmines_no_water.gpkg")
```


Finally, we can sample non-mining areas in the adm1s of interest. For a given adm1, we'll sample 2x the # of mines located in that adm1.
```{r}
set.seed(1236)

adm1s_no_water = adm1s_no_water%>%
  mutate(adm1_id = as.factor(adm1_id), id_pro = paste(gn_name, adm1_id, sep = "_"))

strata_n = setNames(adm1s_no_water$n_sample, adm1s_no_water$id_pro)
non_mining_sample = grts(st_transform(adm1s_no_water, crs_sampling), n_base = strata_n, stratum_var = "id_pro")

non_mining_sample_pts = st_transform(non_mining_sample$sites_base, crs)
st_write(non_mining_sample_pts, "Processed data/Sampling points/non_mining_sampling_pts.gpkg", delete_dsn = T)

rm(non_mining_sample)
```

## Combining
Combine the two.

```{r}
comb_mining_sampling_pts%>%data.frame()
sf_sample_pts%>%data.frame()

all_sampling_pts = rbind(
  comb_mining_sampling_pts%>%mutate(stratum = "mine"),
  sf_sample_pts%>%select(id, gn_name, geonunit)%>%mutate(stratum = "non-mine", primary_commodity = NA))%>%
  rename(adm1_id = id)%>%
  mutate(point_id = row_number())

st_write(all_sampling_pts, "Processed data/Sampling points/all_sampling_pts.gpkg", delete_dsn = T)
all_sampling_pts = st_read("Processed data/Sampling points/all_sampling_pts.gpkg")
```


# Extract covariates

```{r}
# Continuous variables
test = all_sampling_pts %>%
  st_join(., landmark_study_area_full%>%select(Name:Doc_Status)%>%mutate(indigenous = 1), left = T)%>% 
  #st_join(., study_area_adm1s_recog%>%mutate(study_area_recog = 1)%>%select(study_area_recog))%>%
  
  group_by(point_id)%>%
  slice(1)%>%
  ungroup()%>%
  mutate(
    across(c(indigenous, study_area_recog), ~replace_na(.x, 0)),
    treatment_all = indigenous,
    recognised = case_when(
      Form_Rec == "Acknowledged by govt" & Doc_Status == "Documented" ~ 1,
      Form_Rec == "Not acknowledged by govt" | Doc_Status == "Not documented" | grepl("Held or used", Doc_Status) ~ 0),
                           
    treatment_recog = case_when(
      recognised == 1 ~ 1,
      indigenous == 0 & study_area_recog == 1 ~ 0),
    treatment_unrecog = case_when(
      recognised == 0 ~ 1,
      indigenous == 0 & study_area_recog == 1 ~ 0),
  
    road_density = terra::extract(road_density, vect(.))[,2],
    pop_density = terra::extract(pop_dens, vect(.))[,2],
    dist_water = terra::extract(dist_to_water, vect(.))[,2],
    forest_cover = terra::extract(forest_binary, vect(.))[,2],
    cropland_cover = terra::extract(cropland_binary, vect(.))[,2],
    #protected_areas = as.numeric(st_intersects(., protected_areas_full, sparse=F)),
    
    dist_to_maus_km = as.numeric(st_distance(geometry, maus$geom[st_nearest_feature(geometry, maus)], by_element = TRUE)) / 1000,
    dist_to_snp_km = as.numeric(st_distance(geometry, snp$geom[st_nearest_feature(geometry, snp)], by_element = TRUE)) / 1000,
    dist_to_nearest_mine_km = pmin(dist_to_maus_km, dist_to_snp_km),
    dist_to_usgs_km = as.numeric(st_distance(geometry, usgs_deposits$geom[st_nearest_feature(geometry, usgs_deposits)], by_element = TRUE)) / 1000,
    dist_to_mine_or_deposit_km = pmin(dist_to_nearest_mine_km, dist_to_usgs_km))
```

Post-processing with ArcGIS
```{r}
st_write(test, "Processed data/Sampling points/sampling_points_w_covariates.gpkg", delete_dsn = T)
st_write(test, "Processed data/Sampling points/sampling_points_w_covariates.shp", delete_dsn = T)
```

```{r}
protected_arcgis = st_read("Processed data/Sampling points/sampling_points_w_covariates.shp")
test = st_read("Processed data/Sampling points/sampling_points_w_covariates.gpkg")

test = test%>%
  left_join(., protected_arcgis%>%select(point_d, protected)%>%rename(point_id = 1)%>%st_drop_geometry(), by = "point_id")%>%
  mutate(across(c(protected, dist_water, pop_density, road_density), ~if_else(is.na(.), 0, .)),
         #geonunit = ifelse(is.na(geonunit), "Spain", geonunit)
         )
```


# Matching

```{r}
tm_shape(test%>%
  #data.frame()%>%
  filter(is.na(geonunit)))+
  tm_dots()
```

Try different caliber widths for robustness?
Can also try optimal matching as alternative to nearest neighbour
```{r}
match_all = matchit(
  treatment_all ~ road_density + pop_density + dist_water + forest_cover + cropland_cover + protected,
  data = test,
  method = "nearest",
  caliper = 0.2,
  exact = ~ geonunit)

match_recog = matchit(
  treatment_recog ~ road_density + pop_density + dist_water + forest_cover + farmland_cover + protected,
  data = all_points,
  method = "nearest",
  exact = ~ country,
  caliper = 0.2,
  ratio = 3)

match_unrecog = matchit(
  treatment_unrecog ~ road_density + pop_density + dist_water + forest_cover + farmland_cover + protected,
  data = all_points,
  method = "nearest",
  exact = ~ country,
  caliper = 0.2,
  ratio = 3)

matched_recog = match.data(match_recog)
```

Balance checking
```{r}
summary(match_all, standardize = TRUE)
bal.tab(match_all, stats = c("mean.diffs", "ks.statistics"))
love.plot(match_all, threshold = 0.1, abs = TRUE)
```

# Analysis

Consider:
-Fixed effects by country or adm1 (using factor() in regression equation)
-Cluster errors by adm1/country. ex: coeftest(reg_model, vcov = vcovCL(reg_model, cluster = ~adm1))
-

```{r}
match_all_df <- match.data(match_all)%>%
  mutate(mine_within_10km = ifelse(dist_to_nearest_mine_km < 10, 1, 0))

table(match_all_df$mine_within_10km)
table(match_all_df$treatment_all)

model_base = glm(
  mine_within_10km ~ treatment_all + road_density + pop_density +
                forest_cover + cropland_cover,
  data = match_all_df,
  family = binomial())

summary(model_base)

# Clustered SEs by ADM1
coeftest(model_base, vcov = vcovCL(model_base, cluster = ~ geonunit))


# Run McNemar's test
mcnemar.test(table(match_all_df$treatment_all, match_all_df$mine_within_10km))
```

```{r}
# Recognized lands model
model_recog = glm(
  mine_outcome ~ recognized + road_density + pop_density +
                forest_cover + farmland_cover + factor(country),
  data = matched_recog,
  family = binomial())

# Non-recognized lands model
model_nonrecog = glm(
  mine_outcome ~ indigenous + road_density + pop_density +
                forest_cover + farmland_cover + factor(country), 
  data = matched_nonrecog,
  family = binomial()
)

# Compare results
summary(model_recog)
summary(model_nonrecog)
```




# Archive


List of countries for analysis
```{r, eval = F}
countries_df = read.csv("Processed data/data_breakdown_by_country_apr30.csv")

countries_full = as.vector(countries_df%>%filter((landmark %in% c("Full Data", "Indicative areas") | in_garnett == "Yes") & (maus_polygons > 0 | snp_points > 0))%>%pull(country))

countries_recog = as.vector(countries_df%>%filter(landmark == "Full Data" & (maus_polygons > 0 | snp_points > 0))%>%pull(country))
```
